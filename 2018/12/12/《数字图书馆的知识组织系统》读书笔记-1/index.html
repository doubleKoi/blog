<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>《数字图书馆的知识组织系统》读书笔记 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="《数字图书馆的知识组织系统》读书笔记Created by Li Xiaoyu on 2018-10-23 上篇 集成传统知识组织资源，构造图书馆的知识组织系统 第一章 引言第二章 图书馆中的知识组织工具 传统知识组织工具 主题词表 分类法 主题词表和分类法的融合   主题标引和元数据 传统知识组织工具的不足  第三章 数字图书馆知识组织模型 知识组织模型的构造  DLKOM: Digital Li">
<meta name="keywords" content="知识组织 数字图书馆">
<meta property="og:type" content="article">
<meta property="og:title" content="《数字图书馆的知识组织系统》读书笔记">
<meta property="og:url" content="http://yoursite.com/2018/12/12/《数字图书馆的知识组织系统》读书笔记-1/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="《数字图书馆的知识组织系统》读书笔记Created by Li Xiaoyu on 2018-10-23 上篇 集成传统知识组织资源，构造图书馆的知识组织系统 第一章 引言第二章 图书馆中的知识组织工具 传统知识组织工具 主题词表 分类法 主题词表和分类法的融合   主题标引和元数据 传统知识组织工具的不足  第三章 数字图书馆知识组织模型 知识组织模型的构造  DLKOM: Digital Li">
<meta property="og:locale" content="zh">
<meta property="og:updated_time" content="2018-12-12T08:17:43.696Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《数字图书馆的知识组织系统》读书笔记">
<meta name="twitter:description" content="《数字图书馆的知识组织系统》读书笔记Created by Li Xiaoyu on 2018-10-23 上篇 集成传统知识组织资源，构造图书馆的知识组织系统 第一章 引言第二章 图书馆中的知识组织工具 传统知识组织工具 主题词表 分类法 主题词表和分类法的融合   主题标引和元数据 传统知识组织工具的不足  第三章 数字图书馆知识组织模型 知识组织模型的构造  DLKOM: Digital Li">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-《数字图书馆的知识组织系统》读书笔记-1" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/12/《数字图书馆的知识组织系统》读书笔记-1/" class="article-date">
  <time datetime="2018-12-12T08:14:11.000Z" itemprop="datePublished">2018-12-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      《数字图书馆的知识组织系统》读书笔记
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="《数字图书馆的知识组织系统》读书笔记"><a href="#《数字图书馆的知识组织系统》读书笔记" class="headerlink" title="《数字图书馆的知识组织系统》读书笔记"></a>《数字图书馆的知识组织系统》读书笔记</h2><p>Created by <code>Li Xiaoyu</code> on <strong>2018-10-23</strong></p>
<h3 id="上篇-集成传统知识组织资源，构造图书馆的知识组织系统"><a href="#上篇-集成传统知识组织资源，构造图书馆的知识组织系统" class="headerlink" title="上篇 集成传统知识组织资源，构造图书馆的知识组织系统"></a><code>上篇</code> 集成传统知识组织资源，构造图书馆的知识组织系统</h3><hr>
<h4 id="第一章-引言"><a href="#第一章-引言" class="headerlink" title="第一章 引言"></a><code>第一章</code> 引言</h4><h4 id="第二章-图书馆中的知识组织工具"><a href="#第二章-图书馆中的知识组织工具" class="headerlink" title="第二章 图书馆中的知识组织工具"></a><code>第二章</code> 图书馆中的知识组织工具</h4><ol>
<li><strong><u>传统知识组织工具</u></strong><ul>
<li>主题词表</li>
<li>分类法</li>
<li>主题词表和分类法的融合</li>
</ul>
</li>
<li><u><strong>主题标引和元数据</strong></u></li>
<li><strong><u>传统知识组织工具的不足</u></strong></li>
</ol>
<h4 id="第三章-数字图书馆知识组织模型"><a href="#第三章-数字图书馆知识组织模型" class="headerlink" title="第三章 数字图书馆知识组织模型"></a><code>第三章</code> 数字图书馆知识组织模型</h4><ol>
<li><p><strong><u>知识组织模型的构造</u></strong></p>
<ul>
<li>DLKOM: Digital Library Knowledge Organization Model</li>
<li>步骤：<ol>
<li>改造主题词表形成一个抽象的概念网络 </li>
<li>将元数据按照记录它们的主题标引信息分配到概念网络对应的节点中去，作为对应概念的文献实例存储（排架）</li>
</ol>
</li>
<li>概念节点包括：<strong>同义词集</strong>与对应文献的<strong>元数据</strong></li>
<li>:framed_picture:示意图：p19 图 3-1</li>
<li>概念间的三类联系：来自于词表的概念间的组配关系；来自于分类法的概念间的学科相属关系；来自于元数据的概念间的组配关系——统一用<strong>上下位关系</strong>表示</li>
</ul>
</li>
<li><p><strong><u>DLKOM的形式化定义</u></strong></p>
<ul>
<li><p>概念：$$(A, A’)$$  $$A$$表示概念的内涵——同义词集合，$$A’$$表示概念的外延——元数据记录集合</p>
</li>
<li><p>词表：$$Th(W, R_{UF}, R_{NT}, R_{RT})$$ W是词语的集合，后面三个分别代表等同关系、等级关系和相关关系（相关关系可以被简化，词表成为一个三元组）</p>
</li>
<li><p>主题：S 一个同义词的集合，由一个主题词和与它具有等通关系的所有关键词组成<br>一个主题的集合记为$$\Omega$$<br>$$<br>S:={t|t\in Th, t_i\in Th, R_{UF}(t,t_i)}, i\in T, T = [1..n]<br>$$</p>
</li>
<li><p>等级关系：上位关系（BT）和下位关系（NT） $$NT = BT^{-1}$$ 仅使用NT，记为<br>$$<br>R_{NT}(S_i,S_j)或S_i\le S_j<br>$$<br>由此，$$Th$$转化为主题集$$\Omega$$和等级关系$$\le$$形成的偏序集$$(\Omega ,\le )$$</p>
<p>具有等级关系的主题词形成词族。假设每个主题词都只有一个直接上位，主题组形成一个树结构$$Z$$，树根是词表中的极大元素，记为$$\Delta Z$$。每个主题都归入唯一的主题树，偏序集是一个主题树的森林：<br>$$<br>\Omega :=\bigcup_{i=1}^{m}Z_i<br>$$<br>设立森林的顶$$T$$，使得$$T\leq_{直接}\Delta (Z_i), \forall Z_i \subset\Omega$$，加入$$T$$后的集合记为$$\Omega^0$$</p>
<hr>
</li>
<li><p>主题的和运算：$$S_i$$与$$S_j$$的和是二者的共同直接上位，即共同的父节点。广义和：最小共同上位。</p>
</li>
<li><p>主题的积运算：共同直接下位，表示组配的组配主题。广义积：共同下位。复合主题不会再参与构成其他复合主题。</p>
<hr>
</li>
<li><p>语义元数据集：一条语义元数据记录可以看作一个有序对$$(d, A)$$，d是一篇文献，A是标引它的主题词集合。$$A\in \Omega^*$$ </p>
</li>
<li><p>:question:分类法可形式化为$$(M,\leq )$$，$$M$$是类目的集合，$$\leq$$是类目上的偏序关系。在分面分类的情况下，分类法和词表完全结合在一起，每个类目就是一个主题概念，类目之间的等级关系就是主题间的等级关系。在分类主题一体化的情况下，类目与主题不具有一一对应关系。</p>
</li>
</ul>
</li>
<li><p><u><strong>概念的操作</strong></u></p>
<ul>
<li>:question:A*B与A and B的区别</li>
</ul>
</li>
<li><p><u><strong>基于DLKOM的服务机制</strong></u></p>
<ul>
<li>概念检索：传统的关键词查找是考察文献与检索词之间的关系，而基于DLKOM的概念检索考察的是概念间的关系，是依据概念节点间的路径进行检索的。</li>
<li>族性检索</li>
</ul>
</li>
<li><p><u><strong>与关键词检索的比较</strong></u></p>
<ul>
<li><p>关键词检索的缺点：</p>
<ol>
<li>难以准确表达检所需求，影响检索质量</li>
<li>依赖词形匹配而非词义匹配，同义词的查全率难以保证；西文有词形变化</li>
<li>检索结果难以组织和排序</li>
</ol>
</li>
<li><p>检索过程不同</p>
<p>:framed_picture:检索过程：文献资源的收集与组织、用户检索需求的表达、检索处理、检索结果反馈</p>
<p>关键词检索需要提供外置词表来进行同义词查询扩展</p>
</li>
<li><p>检索语义比较</p>
<p>关键词检索的检索语义：$$search(a):={d|d\in D, dIa, a是一个检索词}$$</p>
<p>​                    $$search(a\  and\  b):={d|d\in D, dIa\and dIb}$$</p>
<p>​                    $$search(a\  or\  b):={d|d\in D, dIa\or dIb}$$</p>
<p>DLKOM检索的检索语义<a href="示意图见原书37页">^1</a>：</p>
<p>$$search(a)$$：假设检索词$a$属于概念$A$，则检索结果为概念$A$及由概念A组配成的复合概念所包含的文献。</p>
<p>$search(a\ and\ b)$：$$ext(A*B)\subseteq search(a\ and\ b)\subseteq ext(A\ and\ B)$$</p>
<p>$$search(a\ or\ b)$$：$$search(a\ and \ b)\subseteq ext(A\ and\ B)\subseteq ext(A+B)$$:question:</p>
</li>
</ul>
</li>
<li><p><u><strong>总结与讨论</strong></u></p>
<ul>
<li>对相关关系的处理：如果两个概念相互组配参与了符合主题的构成，它们就是相关的。（否命题不成立，可能<u>暂时</u>不存在使用两个概念共同标引的文献）</li>
<li>并列主题:question:</li>
</ul>
</li>
</ol>
<h4 id="第四章-基于传统知识组织资源构建本体"><a href="#第四章-基于传统知识组织资源构建本体" class="headerlink" title="第四章 基于传统知识组织资源构建本体"></a><code>第四章</code> 基于传统知识组织资源构建本体</h4><ul>
<li><p>本体：描述了某个特定领域的知识模型（由概念和概念间的关系构成），为该领域提供相关的词汇集和推理规则。</p>
</li>
<li><p>DLKOM的构造与本体构建</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Title:DLKOM构造与本体构建的对比</span><br><span class="line">DLKOM构造-&gt;本体构建:DLKOM:集成分类法和词表，将它们转化为一个概念网络\n本体:建模</span><br><span class="line">DLKOM构造-&gt;本体构建:DLKOM:将元数据记录按照主题标引信息分配到网络中对应的节点中去\n本体:导入实例数据</span><br></pre></td></tr></table></figure>
<p>不同点：</p>
<ul>
<li>在本体建模中，文献、作者、出版者等信息都可以被作为概念，DLKOM中的”概念”被扩展为本体中的“类”</li>
<li>DLKOM中将一条元数据作为整体来表示一个文献实例，而本体可以将元数据拆解为更基本的单位（字段）</li>
</ul>
</li>
</ul>
<ol>
<li><u><strong>书目本体的构建</strong></u><ul>
<li>构造本体的出发点是为浏览、检索等应用服务，为网络资源的自动组织服务，而不是为了书目资源的管理、保存、流通等。</li>
<li>斯坦福大学书目本体</li>
<li>DC / DCAM(Dublin Core Abstract Model)，可以通过RDF描述该模型的规范语义。</li>
<li>SKOS( Simple Knowledge Organization System ) by W3C</li>
<li>KVision本体（基于SKOS, RDF, DC)<a href="示例见原书45页">^2</a></li>
</ul>
</li>
<li><u><strong>概念浏览和语义检索</strong></u><ul>
<li>三类操作：基于对象节点、基于节点间关系、结合推理规则。对象是类(概念)，边反应类之间的语义关系</li>
</ul>
</li>
<li><u><strong>利用本体加强搜索引擎</strong></u><ul>
<li>传统搜索引擎的不足：普通用户找不到合适的词汇表达自己的搜索需求；返回的大量搜索结果缺乏组织，完全以来排序</li>
<li>搜索词汇辅助：当用户键入查询词时，一方面将查询词提交给搜索引擎，另一方面将查询词提交给本体，获取该词的上下文概念，方便用扩检和缩检</li>
<li>搜索结果归类：传统的方法是聚类，从命中页面中提取命名实体和主题进行聚类；归类则是参考外部知识库，对专业领域的搜索具有较大的价值。</li>
</ul>
</li>
<li><u><strong>KVision原型系统的实现</strong></u><ul>
<li>数据集：《中国分类主题词表》第一版中计算机领域的主题词集合和TP类表；北京大学图书馆提供的1991-1999年间北京大学图书馆编制的TP类书目数据（5234条）</li>
<li>工具：本体编辑工具Protege、RDF数据管理系统Sesame</li>
<li>步骤：数据预处理与导入→在Java中调用Sesame的API对本体知识库进行操作实现知识浏览和语义检索的功能→包装为网络服务</li>
</ul>
</li>
<li><u><strong>小结</strong></u><ul>
<li>传统的知识组织工具应当尽快转换为机器可以访问、可以自动应用的知识库</li>
<li>不能放弃原有的MARC等传统资源 </li>
</ul>
</li>
</ol>
<h4 id="第五章-DLKOS支持下的服务"><a href="#第五章-DLKOS支持下的服务" class="headerlink" title="第五章 DLKOS支持下的服务"></a><code>第五章</code> DLKOS支持下的服务</h4><ul>
<li>两个应用场景：数字图书馆的检索扩展、企业的知识管理</li>
</ul>
<ol>
<li><p><strong><u>数字图书馆中的概念检索机制</u></strong> </p>
<ul>
<li><p>检索式扩展：通过检索词扩展和语词加权来改进最初的检索式，即向最初的检索式中增加语词。需要用户在检索结果中缩小范围，没有自动化。</p>
</li>
<li><p>自动检索式扩展：考虑用来扩展的语词来源和如何挑选用于扩展的语词</p>
</li>
<li><p>挑选扩展检索词的三种策略：相关语词、反馈语词、交互式选择</p>
</li>
<li><p><strong>虚拟相关反馈（Pseudo Relevance Feedback, PRF)</strong>，不从用户处获得反馈信息，而是从检索出的文献中提取反馈信息。</p>
<p>假设$$q$$表示最初的用户检索式向量空间，$$d_j$$表示文献集合中的一篇文献向量，$$sim(d_j, q)$$表示检索式向量与文献向量的相似度。给定一个阈值$$\theta$$，$$E$$表示检索之后根据给定的阈值选取排列在前面的文献向量集合，即用于语词扩展的文献向量空间：<br>$$<br>E = {d_j^+|(\frac{sim(d_j^+,q)}{\max _i\ sim(d_j,q)})\geq\theta}<br>$$<br>$$d_s$$表示$$E$$所属的文献向量空间的总和：<br>$$<br>\d_s =\sum{d_j^+}\ (d_j^+\in E)<br>$$<br>扩展之后的检索式向量$$q’$$为：<br>$$<br>q’ = \frac{q}{|q|}+\alpha\frac{d_s}{|d_s|}<br>$$<br>其中$$\alpha$$是新加入语词的权值的约束参数，根据新的检索式向量与文献的相似度重新排列文献。</p>
<p>PRF方法很大程度地依赖于被选择用于扩展的语词的质量。</p>
</li>
<li><p><strong>文本聚合( Document Clustering )</strong>：从文本向量空间中提炼出用户的检索需求，用来构造检索语词概念。</p>
<p>这种方法假设文本空间中有一些基本概念，这些基本概念可以组合成检索需要的主题词；假设每个文献都有一些文本特征来表达这些基本概念。</p>
<p>提取特征的步骤：①挑选关键句子 ②将关键句怎分解成特征向量</p>
<p>挑选关键句的标准：①句子在文献中的位置 ②句子中的词在全文中出现的次数 ③一些特殊的词或词族在句子中的出现 ④句子与其他句子、单词、段落的关系</p>
<hr>
<p>基于Luhn的主题词聚合和关键词词频的文本聚合原理：</p>
<ul>
<li><p>根据TF/IDF计算权值，聚合主题词。如果一个词的权值高于阈值$$\theta$$，就认为是主题词。则每个句子的得分为：<br>$$<br>SS1 = \frac{SW^2}{TW}<br>$$<br>其中$$SS1$$为句子的主题词得分，$$SW$$为句子中主题词的数量，$$TW$$为句子中词的总个数（去掉停用词）。</p>
</li>
<li><p>计算关键词词频得分：<br>$$<br>SS2 = \frac{TTS}{TTT}<br>$$<br>其中$$SS2$$为句子关键词得分，TTS为句子中出现的标题单词的总个数，TTT为标题中含有的单词个数。</p>
</li>
<li><p>计算句子总得分：<br>$$<br>SSS = SS1+SS2<br>$$<br> 将关键句分解为特征向量：用关键句中语词的TF/IDF来形成句子的向量，则所有关键句形成的一系列向量为</p>
</li>
</ul>
<p>$$<br>S={s_1,s_2,…,s_m}<br>$$</p>
<p> 将每个$$s_i$$作为一个子图……:question:</p>
<p> 将基本概念向量组合起来构造语词概念：</p>
<ul>
<li>选出与最初的检索式$$q_0$$最相似的10个基本概念向量</li>
<li>从10个基本概念向量中每次最多选出三个组合成$$DNF_s$$（析取范式）</li>
<li>选出与最初检索式最接近的一组组配方式$$DNF_d$$</li>
<li><p>重构检索式$$q=\alpha q_0+\beta d$$，$$\alpha, \beta$$是权值控制值</p>
<p><strong>总结</strong>：改进效果一般，多样本和大样本的效果有待研究</p>
</li>
</ul>
</li>
<li><p><strong>语词关联( Term Co-occurences )</strong>：找出与检索式中语词相关联的语词来扩展检索式。</p>
<p>两种策略：全局检索和局部检索</p>
<p>语词间的三种关系：:question:</p>
<ol>
<li>特有关系：如果$$(\alpha \supset \beta)\and(\alpha \subset \beta(\omega))$$，那么$$\alpha \rightarrow \beta(\omega)$$是特有关系，表明$$\alpha$$比$$\beta$$这个概念更具体。例如大象$\or$狗$\or$马→哺乳动物(0.7)</li>
<li>概括关系：如果$$(\alpha \subset\beta)\and(\alpha \supset\beta(\omega))$$，那么$$\alpha \rightarrow \beta(\omega)$$是概括关系，表明$$\alpha$$比$$\beta$$这个概念更概括。例如哺乳动物$\and$有个长鼻子→大象(0.7)</li>
<li>普遍关系：如果$$(\alpha \supset\beta)\or(\alpha \subset\beta(\omega))$$，那么$$\alpha \rightarrow \beta(\omega)$$是普遍关系，表明$$\alpha$$和$$\beta$$这两个概念有一定的联系。例如科学家→科学(0.4)</li>
</ol>
</li>
</ul>
</li>
<li><p><strong><u>企业知识管理</u></strong></p>
<ul>
<li>数字图书馆：改善大规模网络资源利用困难的情况</li>
<li>知识组织的三个方面：原始信息的对象化和知识化；信息仓储的知识组织（Ontology）；提供个性化增值服务</li>
<li>企业使用数字图书馆进行知识组织的具体内容：<ul>
<li>企业Ontology的创建和维护：知识主管/专家创建语义，从信息仓储中抽取语义</li>
<li>利用企业Ontology对企业的信息仓储进行知识组织形成知识库</li>
<li>提供各类组件化的决策支持工具和知识服务工具</li>
<li>应用数据挖掘工具，挖掘信息库中的隐性知识，补充Ontology和知识库，调整企业的下一步运行</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="第六章-网络知识组织系统"><a href="#第六章-网络知识组织系统" class="headerlink" title="第六章  网络知识组织系统"></a><code>第六章</code>  网络知识组织系统</h4><ul>
<li>网络知识组织系统：Networked Knowledge Organization System, NKOS</li>
<li>语义网：旨在将现有网络发展成为一个数据知识交换与集成、知识化利用与管理的基础环境</li>
<li>NKOS的研究领域：NKOS的表示、互操作、标准化、生成和维护、应用</li>
</ul>
<ol>
<li><p><strong><u>NKOS的类型和表示</u></strong></p>
<ul>
<li><p>NKOS的类型：术语表、分类法和词汇关系网</p>
<p>术语表：线性结构，包括规范档(Authority Files)、专用名词词典(Glossary)、字典(Dictionary)、地名词表(Gazetteer)等</p>
<p>分类法：树状结构，注重主题、学科的集成，揭示等级关系（包括<strong>主题词表</strong>、分类法、专类分类表、类目系统）</p>
<p>词汇关系网：网状结构，除用代属分参关系之外还包含<strong>整体-部分、蕴含、因果</strong>等关系</p>
</li>
<li><p>NKOS的表示</p>
<ol>
<li>电子化：MARC</li>
<li>基于HTML</li>
<li>基于语义网技术：XML、RDF、OWL</li>
</ol>
</li>
<li><p><strong>SKOS</strong></p>
<ul>
<li>SKOS的核心词汇：<ol>
<li>概念(skos: Concept)：ex:love -rdf:type-&gt; skos:Concept</li>
<li>标签(skos:prefLabel, altLabel, hiddenLabel, symbol, prefSymbol, altSymbol)</li>
<li>语义关系属性：语义关系、上位类关系、下位类关系、相关关系；概念框架、属于框架、顶级概念</li>
<li>主题标引属性：主题、是主题、首要主题、是首要主题</li>
</ol>
</li>
<li>SKOS与RDF、OWL的比较：<ul>
<li>SKOS是面向概念框架表示的RDF应用。RDF提供通用的模型，缺乏精确的描述能力；SKOS有针对性</li>
<li>OWL是一种面向本体表示的NKOS语言，同样以RDF为基础，但有强大的描述和推理能力。</li>
</ul>
</li>
</ul>
</li>
<li><p>NKOS的互操作<a href="分类图见原书84页">^3</a></p>
<ul>
<li>解决两个问题：多语言和异构</li>
<li>实现方式：继承/仿建、翻译/改编、卫星子表、直接映射、共现映射、中心转换、临时列表、协议连接</li>
</ul>
</li>
<li><p>相关标准</p>
<ul>
<li>Z39.19：词汇控制</li>
<li>BS8723：电子词表的功能设计、词表管理软件、电子环境下的显示和分面分析</li>
<li>Zthes：描述和传输词表、类表，实现和KOS相关的应用间的互操作性</li>
<li>SKOS</li>
</ul>
</li>
<li><p>NKOS的生成和维护</p>
<ul>
<li>词表的自动生成：挖掘用户日志，挖掘已标引的语料中的知识并建立对应关系</li>
<li>传统分类法的改造：自动分类最大的困难是数据稀疏和错误传播，通过收缩、合并、截枝等操作进行重构</li>
<li>从词表向本体的演化：概念、术语和词串</li>
</ul>
</li>
<li><p>NKOS的应用</p>
<ul>
<li>术语服务</li>
<li>术语映射服务（直接映射、共现映射）</li>
<li>检索辅助</li>
<li>词汇注册</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="中篇-词表的自动丰富机制研究"><a href="#中篇-词表的自动丰富机制研究" class="headerlink" title="中篇 词表的自动丰富机制研究"></a><code>中篇</code> 词表的自动丰富机制研究</h3><hr>
<h4 id="第七章-中国分类主题词表的自动丰富"><a href="#第七章-中国分类主题词表的自动丰富" class="headerlink" title="第七章 中国分类主题词表的自动丰富"></a><code>第七章</code> 中国分类主题词表的自动丰富</h4><ul>
<li>探讨一种从元数据中挖掘新的词汇并将它们定位到手工编制的词表中，对词表进行自动更新的机制</li>
<li>三个步骤：提取关键词、确定抽取出的关键词的专指度、将专指度高的词汇定位在词表中</li>
</ul>
<ol>
<li><p><strong><u>关键词提取</u></strong></p>
<ul>
<li><p>两类方法：基于规则和基于统计，后者是主流，从符号串内部结合的紧密度及对上下文环境的依赖度来判断是否成词</p>
</li>
<li><p>从标题中抽取关键词：标题具有固定句式、标题是文献内容的浓缩</p>
<p>根据两个相邻单字之间的互信息（MI）进行切词，切分部位应该是字串内联系最弱的位置<br>$$<br>MI(ab) = \log_2\frac{P(ab)}{P(a)<em>P(b)}=\log_2\frac{freq(ab)·N}{freq(a)</em>freq(b)}<br>$$<br>其中，P(a)是单字a在语料库中的出现概率，以$$\frac{freq(a)}{N}$$计算，N是数据集的总字数。将英文短语作为一个单独的汉字对待。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">input: 一个标题串，赋值到变量TitlePiece中</span><br><span class="line">output：提取的关键词</span><br><span class="line">procedure KWExtract(TitlePiece)</span><br><span class="line">&#123;</span><br><span class="line">    if(length(TitlePiece)&lt;2)</span><br><span class="line">    	return (null);</span><br><span class="line">    else if(frequency(TitlePiece))&gt;=TH_ext</span><br><span class="line">    	return(TitlePiece);</span><br><span class="line">    else&#123;</span><br><span class="line">        在TitlePiece中寻找MI值最小的bigram作为断点；</span><br><span class="line">        在断点bigram处将TitlePiece切为两段S-1,S-2;</span><br><span class="line">        KWExtract(S-1);</span><br><span class="line">        KWExtract(S-2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 减少计算量的方法：仅当子串s的频率高于指定阈值时，才能被抽出；对包含停用字的bigram进行事先切分</p>
</li>
</ul>
</li>
<li><p><strong><u>专指词度量和新词定位</u></strong>:question:</p>
<ul>
<li><p>对于标题中的关键词，专指度越高，它对标题语义的影响越大，和标引词之间的对应关系就越强；专指度越低，即越通用，对标题语义的影响越小，和标引词之间的对应关系就越弱。</p>
</li>
<li><p>用于新词在词表中的定位：新词与核心概念存在上下位关系或同义关系（如何确定是哪一种关系?:question:）</p>
</li>
<li><p>核心概念计算</p>
<ol>
<li><p>k是一个给定的候选关键词，从包含k的元数据记录中收集标引项，形成标引词集I，即$$I={t|\exists 元数据记录d, k在d的标题中出现，且d被t标引; freq(t)表示t在I中的出现频率}$$</p>
</li>
<li><p>定义I的一个划分$$SI_i(i\in [1,m]), SI_i$$的成员归属于同一个词组$$SF_i$$，即<br>$$<br>\bigcup^m_{i=1}SI_i = I,\ SI_i\subseteq SF_i,\ SF_i是SI_i所对应的词族<br>$$</p>
</li>
<li><p>从每个SI中按照计算主题组的主体代表的算法选出一个主题代表rc, rc的权重等于SI所包含的标引词的频率之和，形成一个主题代表的集合$$S_r$$：<br>$$<br>S_r = {rc_i|1\leq i\leq m,\ freq(rc_i)=\sum^{|S_i|}_{j=1}freq(t_j)}<br>$$</p>
</li>
<li><p>权值高于给定阈值的主题代表被选出，组配成I的核心主题概念cc，即<br>$$<br>cc = {rc|rc\in S_r \and freq(rc)\geq TH_{cs},\ TH_{cs}=\alpha·\sum^{|D|}_{i=1}freq(t_i}<br>$$</p>
</li>
</ol>
</li>
<li><p>计算主题组的主题代表</p>
<ol>
<li><p>设置阈值$$TH_{rc}=\beta · \sum^{|SI|}_{i=1}freq(t_i)(\beta&gt;0.5)$$</p>
</li>
<li><p>选取从词族SF的根到SI中的每一个词的路径，形成一棵子树$$SI_F$$，它叶子结点都来自于SI。定义<br>$$<br>wgt(t_i)=<br>\begin{cases}<br>freq(t_i)&amp; t_i \in SI\<br>0&amp; t_i\in SF_I\and t_i\notin SI<br>\end{cases}<br>$$</p>
</li>
<li><p>从$$SI_F$$的最底层选择一个叶子结点t，若$$wgt(t)&lt;TH_{rc}$$，从$$SI_F$$中删除t，$$wgt(t.parent) = wgt(t.parent)+wgt(t)$$,goto(3)；否则goto(4)</p>
</li>
<li><p>返回t作为SI的主题代表 </p>
</li>
</ol>
</li>
</ul>
</li>
<li><p><strong><u>总结与讨论</u></strong></p>
</li>
<li><ul>
<li>有局限性：从标题中提取关键词，只能适用于科学技术类文献，文艺类文献的标题不能直接反映作品主题——从文摘中提取关键词</li>
<li>应用：改善关键词提取、信息抽取、自动文献、问答系统的技术水平（:question:有无应用实例？）</li>
</ul>
</li>
</ol>
<h4 id="第八章-ADL地理特征词表的自动丰富"><a href="#第八章-ADL地理特征词表的自动丰富" class="headerlink" title="第八章 ADL地理特征词表的自动丰富"></a><code>第八章</code> ADL地理特征词表的自动丰富</h4><ul>
<li><p>Ontology自丰富方法：集成、语义映射、关系扩展、词汇丰富</p>
</li>
<li><p><a href="http://geonames.usug.gov" target="_blank" rel="noopener">USUG地理名称信息系统</a></p>
</li>
<li><p>研究目标：从地名中抽取有检索价值的通用词，并分析它们和标引主题词之间的同现关系，据此在等级层次结构上对地理特征词表进行词汇的丰富与扩充。</p>
</li>
<li><p>地理特征主题词表(Feature Type Thesaurus, FTT)的问题：</p>
<ol>
<li>用户需要预先熟悉词表内容才能进行检索</li>
<li>标引员需要从FTT中选择恰当的主题词对地名进行标引和归类</li>
<li>FTT自身需要不断的维护和更新</li>
</ol>
</li>
<li><p>解决方法：</p>
<ol>
<li>利用名词性词组中的中心语（通用词汇），例如Santa Barbara High School中的High School</li>
<li>分析提取出的词汇和用于标引地名的主题词之间的同现关系，挑选有价值的通用词，并确定与它相关联的主题词，例如High School——educational facilities</li>
<li>根据FTT的等级结构，选出最有价值的表示地理特征的通用词</li>
</ol>
</li>
<li><p>算法设计</p>
<ol>
<li><p>抽词</p>
<p>抽取的词汇需要满足的条件：①是独立的语义单元 ②语义上相对完备</p>
<p>抽取出的词汇在地名库中出现的频次需要大于某个初始阈值，保证一定的语义独立性</p>
<p>利用文本互信息（Pointwise Mutual Information, PMI）辅助寻找地名中名词性词组的边界：<br>$$<br>PMI(w_iw_{i+1})=\log_2\frac{P(w_iw_{i+1})}{P(w_i)P(w_{i+1})}<br>$$<br>其中$$P(w_iw_{i+1})$$是相邻单词$$w_i,w_{i+1}$$的共现概率，$$P(w_i)、P(w_{i+1})$$是$$w_i、w_{i+1}$$各自出现在地名中的概率。采取最大似然估计计算概率：<br>$$<br>PMI(w_iw_{i+1})=\log_2\frac{frequency(w_iw_{i+1})/N}{frequency(w_i)/N·frequency(w_{i+1})/N}<br>$$<br>在PMI最小处作为词组划分的边界，并根据阈值$$\theta$$进行筛选</p>
</li>
<li><p>定位</p>
<p>考察从地名中抽取出的候选词与标引这个地名的主题词之间的关联强度，确定与该候选词关联最密切的主题词</p>
<p>定义候选词$$k$$对集合$$T$$的原始隶属度：<br>$$<br>\mu _T(k) =<br>\begin{cases}<br>\frac{IndexedCount_T(k)}{TokenCount(k)}&amp; \forall k\in U,\ k被t标引<br>\0 &amp;\forall k\in U, \ k没有被t标引过<br>\end{cases}<br>$$<br>其中$$t$$为某一地名主题词，$$T$$为被$$t$$标引的所有候选词的集合</p>
<p>原始隶属度非常小的$$k$$出现在集合$$T$$的边缘附近，这时我们认为$$k与t$$的关联有极大的偶然性与不稳定性。为消除边缘部分的噪音干扰，设定阈值$$\rho$$<br>$$<br>\mu’_T(k)=<br>\begin{cases}<br>\mu_T(k)&amp; \mu_T(k)\geq\rho\<br>0&amp; \mu_T(k)&lt; \rho<br>\end{cases}<br>$$<br>如果一个候选词被多个有共同直接上位的主题词标引，那么可以使用这个直接上位词，由此可以构造一个更复合实际的隶属函数：<br>$$<br>\mu^<em>_T(k)=<br>\begin{cases}<br>\mu_T’(k)&amp; narrow(T)=\Phi\<br>\mu’_T(k)+\sum_R\mu^</em>_R(k)&amp; R=narrow(T)\ne \Phi<br>\end{cases}<br>$$<br>成功定位的条件：</p>
<ol>
<li>$$\mu_T(k)\geq\lambda$$且$$broad(T)=\Phi$$；或者</li>
<li>$$\forall R=narrow(T)$$有$$\mu^<em>_R(k)&lt;\lambda\and \mu^</em>_T(k)\geq\lambda$$且$$broad(T)\ne\Phi$$</li>
</ol>
<p>$$\lambda$$的取值：较高——难找到与之足够关联的主题词；较低——增加选出专有名词的风险。一般至少应大于0</p>
</li>
</ol>
</li>
</ul>
<hr>
<h3 id="下篇-图书分类法自动分类研究"><a href="#下篇-图书分类法自动分类研究" class="headerlink" title="下篇 图书分类法自动分类研究"></a><code>下篇</code> 图书分类法自动分类研究</h3><hr>
<h4 id="第九章-图书分类法自动分类"><a href="#第九章-图书分类法自动分类" class="headerlink" title="第九章 图书分类法自动分类"></a><code>第九章</code> 图书分类法自动分类</h4><ol>
<li><strong><u>研究内容</u></strong><ul>
<li>网络信息资源利用的两大障碍：海量和异构</li>
<li>自动分类的研究成果中遗漏的环节：分类体系。现有分类体系大多在纸质文献的环境下发展起来，为手工分类服务</li>
<li>研究目的：①研究书目数据在是否适用于全文分类算法 ②研究如何调整编目和手工分类规则</li>
<li>研究过程：分析书目数据和分类法类目的分布→进行实验→对DDC结构的研究（缩减、分类、重构）</li>
</ul>
</li>
<li><strong><u>相关研究综述</u></strong><ul>
<li>书目数据分类<ul>
<li>三类方法：基于规则的（知识工程）、基于信息检索的  （将所有类目看做平行的，忽略等级关系）、基于机器学习的（LCC+SVM）</li>
</ul>
</li>
<li>等级分类<ul>
<li>老虎机模型：在分类等级结构中的每一个节点i上分配一个分类器$$C_i$$，负责将到达的分类文档分到i的某个孩子节点上。</li>
<li>主要障碍：错误传播、极不平衡的类分布</li>
</ul>
</li>
</ul>
</li>
<li><strong><u>文本分类</u></strong><ul>
<li>过程：文档索引（词向量）→特征词选择/特征空间降维（文档频率、互信息、卡方:question:）→分类器学习→分类和评测</li>
<li>微观平均和宏观平均：微观平均给予每个文档同样的重要度，宏观平均给予每个类同等的重要度</li>
<li>分类算法：朴素贝叶斯，kNN，SVM</li>
</ul>
</li>
<li><strong><u>小结</u></strong><ul>
<li>现有文本自动分类面对的困难：<ul>
<li>有限的文本信息：书目数据的信息量有限</li>
<li>复杂的MARC格式和不一致的标引：对字段有所取舍</li>
<li>庞大的等级结构：DDC深度达20余层</li>
<li>不平衡的分布：数据稀疏问题</li>
<li>分类结果评测：根据分类结果与真实结果的相似度定义lost function?</li>
<li>现实应用</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="第十章-数据分析"><a href="#第十章-数据分析" class="headerlink" title="第十章 数据分析"></a><code>第十章</code> 数据分析</h4><ol>
<li><strong><u>数据集介绍</u></strong><ul>
<li>数据准备：DDC类号、DDC词汇索引、主题词</li>
</ul>
</li>
<li><strong><u>MARC字段抽取</u></strong><ul>
<li>要求：大部分书目都存在的字段，能够将不同书目区分开的字段</li>
<li>三类字段：①标题和标题相关字段 ②结构化的和内容相关的注释（接近全文） ③主题标引字段</li>
<li>最终被采纳的字段：正标题字段、与标题相关的字段、主题标引字段</li>
</ul>
</li>
<li><strong><u>对DDC的分析</u></strong><ul>
<li>自动分类的挑战<ul>
<li>规模大，难以归纳每一个类的特征（generative/discriminitive:question:)</li>
<li>分类深入，深度多达20余层</li>
<li>有些书有多个主题，但为了排架需要选择一个首要类号，给分类带来误导</li>
<li>DDC的类号在不断发生变化</li>
<li>DDC在分类时会考虑形式、物理载体、作者等非主题因素</li>
<li>分类规则复杂，有时会根据本地馆藏重新定义</li>
<li>一个主题可能分散在若干各类中</li>
</ul>
</li>
<li>自动分类的优势<ul>
<li>广泛的可获取性</li>
<li>十进制的类号清晰地反映了主题之间的关系</li>
<li>基于学科结构，而非藏书量</li>
<li>严格的等级结构，确定唯一一条路径</li>
</ul>
</li>
<li>书目数据的挑战<ul>
<li>多个DDC版本</li>
<li>无法解析DDC号的结构（无法确定基号和分面的边界）——将每个DDC号作为一个完整的标识符</li>
<li>编目错误</li>
</ul>
</li>
</ul>
</li>
<li><strong><u>数据分布</u></strong><ul>
<li>4-8层之间文献的分布最密集，容纳了75%的文献</li>
<li>5-11层之间类的分布最密集，容纳了83.6%的类</li>
<li>书目数据的类分布遵从幂律分布</li>
</ul>
</li>
</ol>
<h4 id="第十一章-实验环境的优化"><a href="#第十一章-实验环境的优化" class="headerlink" title="第十一章 实验环境的优化"></a><code>第十一章</code> 实验环境的优化</h4><ol>
<li><p><strong><u>文本规范化</u></strong>：大写转换、去除停用词、取词根</p>
</li>
<li><p><strong><u>索引策略</u></strong>（构建向量）</p>
<ul>
<li>$$d_j={w_{1j},w_{2j},…w_{|T|j}}$$,其中$$T$$是在训练集中至少出现过一次的词汇（特征）集合（维度太高了:question:）</li>
<li>$$0\leq w_{kj}\leq 1$$衡量词汇$$t_k$$对文献$$d_j$$语义的贡献程度</li>
<li>考虑使用单字还是词组作为词汇的基本单位</li>
<li>考虑如何计算权重：二值/TF-IDF</li>
</ul>
</li>
<li><p><strong><u>特征词汇空间</u></strong></p>
<ul>
<li>确定哪一个MARC字段应当被用来构建特征空间</li>
<li>确定索引策略</li>
<li>特征词选取方法：信息增益、TF-IDF、卡方、互信息都不够适用（词语出现次数太少）；Manning提出去掉那些最多在$$k(1\leq k\leq 3)$$篇文档中出现的词汇</li>
</ul>
</li>
<li><p><strong><u>训练集和测试集的划分</u></strong></p>
<ul>
<li><p>k-fold cross validation</p>
</li>
<li><p>将一个类的文档尽量平均分配到k个子集中的方法：先给整个数据集中的文档分配一个全局的序号，子集合$$S_i$$由所有序号取模k后余数为i的文档构成。全局序号$$d_l$$的计算方法：<br>$$<br>gn(d_l)=\sum^{k-1}_1size(c_k)+l<br>$$<br>其中，$$c_k$$是$$d_l$$所属的类，$$size(c_k)$$是类$$c_k$$用其内的文档总数衡量的类的大小，$$k$$是$$c_k$$在所有类集合中按照类的大小排列而得的序号，$$l$$是文档$$d_l$$在类$$c_k$$中的本地序号</p>
</li>
</ul>
</li>
<li><p><strong><u>文本自动分类算法</u></strong></p>
<ul>
<li>SVM是二分类算法<ul>
<li>对于one-against-rest，如果分到正例类中，则正例类得一分，反之则所有反例类各得一分</li>
<li>对于one-against-one，构造$$n(n-1)/2$$个分类器</li>
</ul>
</li>
</ul>
</li>
<li><p><strong><u>参数调整</u></strong></p>
<ul>
<li>SVM在不平衡的数据集上产生的分类模型的分类边界会偏向稀疏类</li>
</ul>
</li>
<li><p><u><strong>基于深度的评测方法</strong></u></p>
<ul>
<li>根据正确类的关系和分类结果的相似度来衡量错误的程度<br>$$<br>similarity(c_i,c_j)=\frac{2·depth(LCA(c_i,c_j))}{depth(c_i)+depth(c_j)}<br>$$<br>$$LCA(c_i,c_j)$$是这两个节点在等级结构U中深度最深的共同祖先</li>
</ul>
</li>
<li><p><strong><u>对比实验</u></strong></p>
<ul>
<li>测试主题标引子字段的组合方式、比较特征词汇空间的各种构造方式、对比三种分类算法的分类效果</li>
<li>减少计算复杂度的措施：①在BDLIC上执行 ②采用缩减的DDC类号 ③应用全局特征词汇降维的方法 </li>
<li>减少后：共有387个类，每个类至少有4篇文档，最深的类位于第14层</li>
<li>SVM采用RBF核函数，参数C和$$\gamma$$通过grid-search确定最优值</li>
</ul>
<ol>
<li><p>主题标引串的组合方式</p>
<p>结果：除了$$1^{st}$$\$a\$a外，在相同的特征词汇空间构造模式下，仅采用第一个主题标引字段比采用所有的主题标引字段的分类效果好；只采用第一个主题标引串而且不加分解($$1^{st}\$a\$a\$a\$x…$$)在各种指标下分类效果都最好（但不能就此下结论，只出现了一次的分类号被删除了，加入进来可能会被错分）</p>
<p>最后选择$$all\$a\$a,\$a\$x,…作为标引模式，这种模式可以从主题标引字段获得最多的主题词，并且从标题和主题字段提取的词汇易于合并</p>
</li>
<li><p>特征词汇空间的比较</p>
<ol>
<li>先确定索引策略：title words / title phrases?</li>
<li>再确定是否需要做特征提取（降维）：是否筛选掉只出现一次的词汇（能否用PCA、word2vec等降维方法:question:）</li>
<li>结果：用词组表示文档向量有助于提高分类效果（与全文不同，书目中能提取的词汇有限，词组可以提高文档向量描述的专指度）；FS_SH（subject headings）有最佳的分类效果，验证了主题索引对主题分类的价值。</li>
</ol>
</li>
<li><p>分类算法的比较</p>
<ul>
<li>效果：SVM&gt;kNN&gt;Naive Bayes</li>
<li>效率：Naive Bayes&gt;SVM&gt;kNN</li>
<li>当主题词和标题词混用时，SVM有了更大的搜索空间，但增加了贝叶斯的噪音。:question:</li>
</ul>
</li>
</ol>
</li>
</ol>
<h4 id="第十二章-分类法结构的改造"><a href="#第十二章-分类法结构的改造" class="headerlink" title="第十二章 分类法结构的改造"></a><code>第十二章</code> 分类法结构的改造</h4><ul>
<li>两个方面：缩短DDC类号、改造DDC的类结构</li>
</ul>
<ol>
<li><strong><u>平面分类和DDC类号的缩减</u></strong><ul>
<li>存在的问题：<ul>
<li>数据的稀疏性，无法训练出有效的分类器</li>
<li>DDC的类比主题标引更深入，无法根据主题标引分到准确的类上</li>
</ul>
</li>
<li>解决方案：缩短DDC类号</li>
<li>好处：<ul>
<li>让每一个类有足够的训练实例</li>
<li>让一个DDC类号的专指度不超过标题和主题标引信息所描述的程度</li>
<li>减少参与分类的类的数量</li>
</ul>
</li>
<li>缩减类号的基本思想：每次缩减一位，直到它具有足够的文档数（过程中需验证类号的有效性） </li>
</ul>
</li>
<li><strong><u>等级分类</u></strong><ul>
<li>平面分类在大规模数据集上的缺点：所有类都被认为是独立的，计算复杂度与类的数量成正比</li>
<li>老虎机等级分类模型</li>
<li>在相同条件下，等级分类不可能比平面分类更准确。原因：<ul>
<li>平面分类器可以辨别任意两个类之间的差异</li>
<li>等级分类器中，对应类C的分类器混淆了C自身的特征，增加了噪音</li>
</ul>
</li>
<li>在稀疏类上效果差</li>
<li>缺点：<ul>
<li>错误传播：即使每个分类器可以达到90%以上的准确度，五层分类器的准确率不超过$$(0.9)^5=0.59$$</li>
<li>稀疏类和不平衡的分布</li>
<li>内部结点的分类：虚拟类树加剧了文档在类结构上的不平衡分布（虚拟节点只有该节点的文献，其他节点包含子类文献）</li>
</ul>
</li>
</ul>
</li>
<li><u><strong>交互分类和DDC的重构</strong></u><ul>
<li>采用人工辅助的方法提高分类效果，但要尽量降低人工干预的次数，同时不损害分类准确率。</li>
<li>交互分类模型：深入到哪一级、朝哪个方向深入由用户决定</li>
<li>参数：n——用户和系统交互的次数，m——在和用户交互的一轮中返回的候选类的数量<ul>
<li>当n=|U|-1，m=每一轮分类中当前节点的子节点数目时，每深入一层就需要和用户交互一次，并且每次需要从当前所有可选类中选取一个合适的类，交互分类变为手工分类；</li>
<li>当n=0,m=1时，不需要和用户交互，每次系统只返回一个类，交互分类变为全自动分类</li>
</ul>
</li>
<li>DDC的重构及剪枝算法<ul>
<li>假设一个分类树的高度为4，如果将n设置为2，则相当于将分类树每两层压缩为一层，将U变换为U’<a href="示意图见原书180页">^4</a></li>
<li>合理的重构类等级层次结构的方法应当满足条件：<ul>
<li>缩减类的层次深度（缓解错误传播的问题，在分类效率和准确率之前寻找平衡）</li>
<li>预测分类的区域而不是准确的点</li>
<li>重塑分类树：将稀疏的叶子节点和支脉合并起来，形成一个密集的区域；将密集的分支削减下来形成单独的子树以降低主干的密度</li>
</ul>
</li>
<li>剪枝算法<ol>
<li>从分类树U的最底层选择一棵高度只有一层的子树$$T_i$$；</li>
<li>对于$$T_i$$上的任意一个节点c，如果c是一个稀疏类，将它合并到$$T_i$$的根节点中；</li>
<li>经过合并后如果$$T_i$$是一棵密集树，则将它减下来，否则将它拉平；</li>
<li>跳转到步骤（1）直到达到U的根节点；</li>
<li>将剪枝后形成的所有的节点包连接成一棵虚拟树U’，连接的位置关系参考将它们从U上剪下来时的位置</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="第十三章-讨论"><a href="#第十三章-讨论" class="headerlink" title="第十三章 讨论"></a><code>第十三章</code> 讨论</h4><ul>
<li>进一步提高分类性能的途径：<ul>
<li>使用简略版DDC</li>
<li>跟踪DDC不同版本间的差别， 将不同版本的类号映射到一个统一的DDC版本上</li>
<li>在DDC重构时加入人工干预，在专家的监督下进行改造</li>
</ul>
</li>
<li>未来研究方向<ul>
<li>加入基于规则的分类，对非主题信息进行利用</li>
<li>DDC实质上是一个知识库，对知识库进行挖掘辅助学习</li>
<li>在其他图书分类法上进行自动分类</li>
</ul>
</li>
<li>对图书馆工作的建议<ul>
<li>在编目时，考虑对自动分类的影响</li>
<li>指示复合分类号的内部结构</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/12/《数字图书馆的知识组织系统》读书笔记-1/" data-id="cjpkwjyqh0000rz5gyf9j28nq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/知识组织-数字图书馆/">知识组织 数字图书馆</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/12/11/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/知识组织-数字图书馆/">知识组织 数字图书馆</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/知识组织-数字图书馆/" style="font-size: 10px;">知识组织 数字图书馆</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/12/《数字图书馆的知识组织系统》读书笔记-1/">《数字图书馆的知识组织系统》读书笔记</a>
          </li>
        
          <li>
            <a href="/2018/12/11/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Sherry<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>